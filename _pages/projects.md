---
layout: page
title: Projects
---

## Papers

<div class="conference-details">
    <div class="paper-title">Decay and non-decay for the massless Vlasov equation on subextremal and extremal Reissner-Nordstr√∂m black holes</div>
    <div class="paper-authors">M. Weissenbacher</div>
    <div class="paper-conference">Accepted to Archive for Rational Mechanics</div>
    <div class="paper-link"><a href="https://arxiv.org/abs/2303.15338">Link</a></div>
</div>

## Conferences

<div class="conference-details">
    <div class="paper-title">Drag reduction for heavy road vehicles with rear flaps</div>
    <div class="paper-authors">X. Jiang, J. Zhang, M. Weissenbacher, I. Fumarola and G. Rigas</div>
    <div class="paper-conference">Presented at European Drag Reduction and Flow Control Meeting, 2024</div>
</div>

<div class="conference-details">
    <div class="paper-title">Static and Dynamic Control for Wind Farm Wake Steering using LES</div>
    <div class="paper-authors">A. Mole, M. Weissenbacher, S. Laizet</div>
    <div class="paper-conference">Presented at 1st European Fluid Dynamics Conference, 2024</div>
</div>

<div class="conference-details">
    <div class="paper-title">Reinforcement Learning of Active Flow Control in Partially Observable Environments</div>
    <div class="paper-authors">M. Weissenbacher, A. Borovykh and G. Rigas</div>
    <div class="paper-conference">Presented at ERCOFTAC ML4FLUID workshop, 2024</div>
</div>

<div class="conference-details">
    <div class="paper-title">CHAROT: Robustly controlling chaotic PDEs with partial observations</div>
    <div class="paper-authors">M. Weissenbacher, A. Borovykh and G. Rigas</div>
    <div class="paper-conference">Presented at ICLR Workshop on AI4Differential Equations In Science, 2024</div>
    <div class="paper-link"><a href="https://openreview.net/pdf?id=SytuCWihJr">Link</a></div>
</div>


## Teaching

I taught week 7 of Dr. Anastasia Borovykh's course on Mathematical Foundations of Machine Learning at Imperial College London, spring term 2024. 

The lecture introduces the idea of contrastive learning, a type of self-supervised learning.
It discusses common types of contrastive losses and their interpretations, along with many applications and pitfalls to watch out for.

Take a look at the [lecture slides](../contrastive_loss_lecture_for_website.pdf) and the accompanying [Jupyter notebook](https://colab.research.google.com/drive/11cScGPESCBuMwtVJ7O7yMH2dALlYp5Yi?usp=sharing), where we implement the SimCLR loss from scratch.
